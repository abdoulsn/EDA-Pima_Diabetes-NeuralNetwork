{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST MKT_MST_TP2.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdoulsn/EDA-Pima_Diabetes-NeuralNetwork/blob/master/V0_MNIST_MKT_MST_TP2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_UvVJOP9uJi"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmaMgUEd9xpm"
      },
      "source": [
        "import numpy as np\n",
        "import datetime, os\n",
        "from tensorflow.keras.utils import get_file\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy, CategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
        "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "\n",
        "!wget https://github.com/camsovangauthier/coursesNN/raw/main/Fashion_MNIST_5classes_augmentation.h5\n",
        "!wget https://github.com/gaudel/NN/raw/main/pretrained_model.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMLafIyo92_m"
      },
      "source": [
        "# Usefull functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpPNMeZf91h4"
      },
      "source": [
        "def build_CNN(input_dim, output_dim, lr=0.001):\n",
        "    ''' Docstring\n",
        "    input_dim: le dim de la data en input\n",
        "    output_dim: la derniere couche qui doit correspondre à 2 (on a 2 type de fashions)\n",
        "    lr: taux de learning rate\n",
        "    '''\n",
        "    model = Sequential()\n",
        "    #Q1: Compléter ici\n",
        "    model.add(Conv2D(32, (3, 3), input_shape=input_dim, name=\"couche1\"))\n",
        "    model.add(MaxPooling2D((2,2)),)\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Conv2D(64, (3, 3),activation='relu', name=\"couche2\"))\n",
        "    model.add(MaxPooling2D((2,2)))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Conv2D(64, (3, 3),activation='relu', name=\"couche3\"))\n",
        "    model.add(MaxPooling2D((2,2)))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Flatten(name=\"flatten\"))\n",
        "    model.add(Dense(64, activation='relu',name=\"couche4\" )) \n",
        "    model.add(Dropout(0.3)) #pour désactiver les neurones non significatifs (30 %), allège le réseau de neurones,évite le sur-apprentissage\n",
        "    model.add(Dense(output_dim, activation='softmax', name=\"couche_sftmx\"))\n",
        "\n",
        "    #Q1: Compilation du modèle\n",
        "    opt = RMSprop(learning_rate=0.01)\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDc2yvL3eie6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssOnACajXiSb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZHzQpPU9-a3"
      },
      "source": [
        "def build_CNN_from_pretrained(file_name, output_dim, lr=0.01):\n",
        "    # Q4: compléter l'appel à la fonction load_model()\n",
        "    model = load_model(file_name)\n",
        "    # Q4: retirer et ajouter la/les couches nécessaires ici\n",
        "    model.pop()\n",
        "    model.pop()\n",
        "    model.add(Dense(2, activation='softmax', name=\"couche_sftmx\"))\n",
        "\n",
        "    # Q4: Compilation du modèle\n",
        "    return model\n",
        "build_CNN_from_pretrained(\"/content/Fashion_MNIST_5classes_augmentation.h5\", output_dim=(150,150,3)).summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELdBI7nO-EGl"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0ZKHTPF-uBt"
      },
      "source": [
        "## Hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDmb1ezx-sjF"
      },
      "source": [
        "epochs = 50\n",
        "batch_size = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5aXh-otABjp"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UorhZH0LAD_f"
      },
      "source": [
        "rng = np.random.default_rng()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxrWMoei-G7N"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "az2KhSRiv5p7"
      },
      "source": [
        "### Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UMXiuTav50U"
      },
      "source": [
        "data_f = get_file('data_fashion.zip', 'https://github.com/camsovangauthier/coursesNN/raw/main/data_fashion.zip', extract=True)\n",
        "\n",
        "def foo(data_src):\n",
        "  if type(data_src) == str:\n",
        "    images, labels = next(ImageDataGenerator(rescale=1./255).flow_from_directory(data_f[:-4] + '/' + data_src, batch_size=25))\n",
        "  else:\n",
        "    images, labels = next(data_src)\n",
        "  print(f'shape of features: {images.shape[1:]}')\n",
        "  print(f'shape of labels: {labels.shape[1:]}')\n",
        "  class_names = ['Bag', 'Dress']\n",
        "  plt.figure(figsize=(10,10))\n",
        "  for i in range(25):\n",
        "      plt.subplot(5,5,i+1)\n",
        "      plt.xticks([])\n",
        "      plt.yticks([])\n",
        "      plt.grid(False)\n",
        "      plt.imshow(images[i], cmap=plt.cm.binary)\n",
        "      plt.xlabel(class_names[np.argmax(labels[i])] + f' ({labels[i]})')\n",
        "  plt.show()\n",
        "\n",
        "# print('--- train data ---')\n",
        "# foo('train')\n",
        "\n",
        "# print('--- validation data ---')\n",
        "# foo('valid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yv9w3_Qzv5-3"
      },
      "source": [
        "### Data generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXJTLXQMfVrN"
      },
      "source": [
        "#Q2: Ajouter l'attribut rescale aux générateurs\n",
        "#Q3: Ajouter des attributs pour faire de l'augmeentation de données\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=40, width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2, shear_range=0.2, zoom_range=0.2,\n",
        "                                   horizontal_flip=True, fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "#Q2: Ajouter les attributs \"target_size\" et \"batch_size\"\n",
        "train_flow = train_datagen.flow_from_directory(\n",
        "        data_f[:-4]+'/train',                   # Source de la train\n",
        "        target_size=(150, 150),                 # toutes les images retaillée à 150x150\n",
        "        class_mode='categorical')               # Pour le binary_crossentropy loss labels\n",
        "\n",
        "valid_flow = test_datagen.flow_from_directory(\n",
        "        data_f[:-4]+'/valid',\n",
        "        target_size=(150, 150),\n",
        "        class_mode='categorical')\n",
        "\n",
        "print('--- train data ---')\n",
        "foo(train_flow)\n",
        "\n",
        "print('--- validation data ---')\n",
        "foo(valid_flow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDwbjjBADR5t"
      },
      "source": [
        "## Build"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTfbZm_kDSCJ"
      },
      "source": [
        "from_scratch = True\n",
        "if from_scratch:\n",
        "  # Q2: compléter l'appel à la fonction build_CNN()\n",
        "  cnn_model = build_CNN(input_dim=train_flow.image_shape, output_dim=2,lr=0.001)\n",
        "  label = 'from_scratch'\n",
        "else:\n",
        "  cnn_model = build_CNN_from_pretrained(\"/content/Fashion_MNIST_5classes_augmentation.h5\", output_dim=(150,150,3))\n",
        "  label = 'from_pretrained'\n",
        "\n",
        "\n",
        "cnn_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBsopydYDSKT"
      },
      "source": [
        "## Fit & evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6TCTaEzDSS2"
      },
      "source": [
        "#Q2: compléter l'appel aux fonctions fit() et evaluate()\n",
        "tensorboard_callback = TensorBoard(log_dir='logs/' + label + '__' + datetime.datetime.now().strftime(\"%d-%m_%Hh%M\"),\n",
        "                                   histogram_freq=int(epochs/10))\n",
        "\n",
        "cnn_model.fit_generator(train_flow, validation_data = valid_flow, epochs=20)\n",
        "\n",
        "cnn_model.evaluate(verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8uvrEd9kCty"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQ1mhkw--mzg"
      },
      "source": [
        "# Tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TK-4z9vk_byM"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENhrAk2iDyy4"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqbcweOUBcd7"
      },
      "source": [
        "## Start tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCV7neA9-vhT"
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}